model_name: "meta-llama/Llama-2-70b-chat-hf"
quantized: True
model_parallelism: True

custom_prompt: "Answer the question.<n><n><icl_demo>Question: <question><n>Answer:"
metric_name: BEM

icl_demo_prompt: "Question: <question><n>Answer: <answer><n><n>"
icl_n: 10
icl_dataset_path: "data/icl/<subset>.parquet"

subset: "TriviaQA-web"
dataset_path: "data/test/<subset>.parquet"
dataset_length: null


correct_examples_path: null
wrong_examples_path: "data/<model_name>/cb_wrong/<subset>.parquet"
full_examples_path: null

output_path: "results/<model_name>/cb_<subset>.out"
