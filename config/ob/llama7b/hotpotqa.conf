model_name: "meta-llama/Llama-2-7b-chat-hf"
quantized: True
model_parallelism: True

custom_prompt: "Answer the question with as few words as possible by extracting information directly from the context.<n><n>Context: <context><n>Question: <question><n>Answer:"
metric_name: "BEM"
sameness_metric: "EM"

dataset: "HotpotQA"
dataset_path:  "data/<model_name>/conflict/<dataset>.parquet"
dataset_length: 100

results_dir: "data/<model_name>/ob"
output_path:  "results/<model_name>/ob _<dataset>.out"
