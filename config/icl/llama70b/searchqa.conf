model_name: "meta-llama/Llama-2-70b-chat-hf"
quantized: True
model_parallelism: True

custom_prompt: "Answer the question concisely using the context.<n><n><icl_demo>Context: <context><n>Question: <question><n>Answer:"
metric_name: "BEM"
sameness_metric: "EM"

icl_demo_prompt: "Context: <context><n>Question: <question><n>Answer: <answer><n><n>"
icl_n: 5

dataset: "SearchQA"
dataset_path:  "data/<model_name>/conflict/<dataset>.parquet"
dataset_length: null

results_dir: "data/<model_name>/icl"
output_path:  "results/<model_name>/icl_<dataset>.out"
